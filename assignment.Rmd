---
title: "Assignment 2"
author: "Cole"
date: '2019-02-07'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


<b> Question 1) </b>
```{r}
p1 <- 1/8 + 1/8
p2 <- 1/4 + 3/8
p3 <- 1/8 + 1/4
p4 <- 1/8 + 3/8
p5 <- 1/8 + 1/8
p6 <- 1/8 + 3/8
p7 <- 1/4 + 1/8
p8 <- 1/4 + 1/8 + 3/8 + 1/8





print(p1)
print(p2)
print(p3)
print(p4)
print(p5)
print(p6)
print(p7)
print(p8)

```

b.) 
```{r}
m1 <- 8*mean(c(1,4,7,7))
m2 <- 8*mean(c(2,4,7,8))
m3 <- 8*mean(c(1,4,7,8))
m4 <- 8*mean(c(2,4,7,8))
m5 <- 8*mean(c(4,7,7,8))
means <- c(m1, m2, m3, m4, m5)
table(means)
hist(means, freq = FALSE, breaks = 20)
```









<b> Question 2) </b>

a.) The data is right tailed, and looks like it follows more of an exponential distribution.  
```{r}
df <- c(rep.int(0,28), rep.int(1,4), rep.int(2,3), rep.int(3,4), rep.int(4,4), rep.int(5,2), 
        rep.int(6,1),rep.int(8,2), rep.int(9,1), rep.int(10,1) )
hist(df)
```

b.) 
```{r}
mean(df)
se <- sqrt(((807-50)/807)*sd(df)**2/50)
print(se)
```


c.) 
 The mean should be starting to approximate a normal distribution as the sample size is sufficiently large. We would expect the mean to converge to a normal distribution more quickly if the parent distribution was more symmetrical.
 
 A confidence interval for the mean is below
```{r}
lowerbound <- mean(df) - qt(.975, 49)*se
upperbound <- mean(df) + qt(.975, 49)*se
print(lowerbound)
print(upperbound)
```
 Confidence interval is (1.04 ,2.52). 
 
 
 



<b> Question 3) </b>
```{r}
print(sqrt((1/400)*(1-400/4000)))
print(sqrt((1/30)*(1-30/300)))
print(sqrt((1/3000)*(1-3000/300000000)))
```
3 will give the most precise estimate as it's standard error is the smallest


<b> Question 4) </b>

```{r}
df <- c(rep.int(9,13), rep.int(10,35), rep.int(11,44), rep.int(12,69), rep.int(13,36), rep.int(14,24), 
        rep.int(15,7),rep.int(16,3), rep.int(17,2), rep.int(18,5), 19, 20 )
hist(df)
```

b.) 
```{r}
mean <- mean(df)
sd <- sd(df)
se <- sd/sqrt(240)
lowerbound <- mean - qt(.975, 239)*se
upperbound <- mean + qt(.975, 239)*se
print(lowerbound)
print(upperbound)

```

c.) 
```{r}
z <- qnorm(.975)
n <- (z*sd/0.5)**2
print(n)
```
57 is the minimum sampe size needed since the population is infinite. 


<b> Question 5) </b>

a.)
```{r}
library(SDaA)
golf <- golfsrs
hist(golf$wkday9)
```

Right tailed data, similar to exponential distribution. 

b.) 
```{r}
mean <- mean(golf$wkday9)
sd <- sd(golf$wkday9)
se <- sqrt(((14938-120)/14938)*sd**2/120)
print(se)
```

```{r}
table(is.na(golf$wkend18))
p <- 85/120
me <- qnorm(.975)*sqrt((p*(1-p))/(120-1)*((14938-120)/14938))
lowerbound <- p - me 
upperbound <- p + me
print(lowerbound)
print(upperbound)
```
From this sample, we can be 95% confident that the true proportion of golf courses in the population that have 18-holes is between 0.627 and 0.79. 


<b> Question 6) </b>

Buckeye 

```{r}
n <- (1.96**2)*((1/2)**2)/(.04)^2
n <- n/(1+n/4857)
```
A sample of 535 is needed. The FPC is needed for Buckeye


Pheonix
```{r}
n <- (1.96**2)*((1/2)**2)/(.04)^2
n <- n/(1+n/1149417)
```

600 sample size is needed. The population size is large enough that the FPC is negligible. 




<b> Question 7) </b>


a.)
```{r}
n <- 100000000/1000
print(1/n)
```
Probability of 0.00001 of being chosen


b.) 
```{r}
p <- 1/n
pbinom(0,2000,p)
```
98% chance of not being chosed in 2000 samples



c.) 

choose(n,0)*(1-0.00001)^n = 0.5
```{r}
n <- log(2)/(5 *log(2) - 2* log(3) + 5* log(5) - log(41) - log(271))
```
69,315 samples are needed to have a 0.5 probability of being included


<b> Question 8) </b>

```{r}
library(ggplot2)
studentsurvey <- read.csv("Desktop/studentsurvey.csv")
ggplot(studentsurvey, aes(x=HSAverage)) + geom_histogram(aes(y=..density..), colour="black", fill="white")+
 geom_density(alpha=.2, fill="#FF6666") 
```

Unimodal distribution, left tailed with significant outlier on the left hand side

b.) 
```{r}
mean <- mean(studentsurvey$HSAverage)
sd <- sd(studentsurvey$HSAverage)
se <- sqrt(((1100-109)/1100)*sd**2/109)
me <- qt(.975, 108)*se
lowerbound <- mean - me
upperbound <- mean + me
print(lowerbound)
print(upperbound)
```
Given this data, we can be 95% confident that the mean HS grade of the 1100 students is between 84.52 and 86.44. 

<b> Question 9) </b>
a.)
```{r}
table(studentsurvey$DiffFees)
p <- 55/109
se <- sqrt((p*(1-p)/(108))*((1100-109)/1100))
me <- qnorm(.975)*se
lowerbound <- p - me
upperbound <- p + me
print(lowerbound)
print(upperbound)
```
Given this data, we can be 95% confident that the proportion of students in the first-year statistics class that approve of the fees is somewhere between 0.415 and 0.594. 




b.) 
```{r}
qnorm(.985)
n <- (1100*p*(1-p))/((1100-1)*(.05/2.17)**2 + p*(1-p))
n
```
A sample size of 330 is needed for these parameters. 



<b> Question 10) </b>

```{r}
table(studentsurvey$MariUse)

p <- 23/109
se <- sqrt((p*(1-p)/(108))*((1100-109)/1100))
me <- qnorm(.975)*se

lowerestimate <- (p-me)*109
upperestimate <- (p + me)*109
print(lowerestimate)
print(upperestimate)

```
Given this data, we can be 95% confident that the total number of students in the first-year statistics course that have smoked marijuana in the past 6-months is between 15 and 31. 



<b> Question 11) </b>

```{r}
q11 <- read.csv("Desktop/Q11.csv")
colnames(q11)

ggplot(q11, aes(x=Fast_Food_Res, y=Order_Completion)) + 
  geom_boxplot()
```
 Restaurant A appears to have significantly lower wait times, with it's Q3 measure nearly below the Q1 measure of Restaurant B. Additionally, A appears to have a more even distribution with it's median closer to the middle than B. Restaurant A also has more outlier values than B. 
 
 
 b.) Null hypothesis: meanA - meanB = 0
     Alt hypothesis : meanA- meanB < 0
     
c.) 
```{r}
resA <- subset(q11, q11$Fast_Food_Res == "ResA")
resB <- subset(q11, q11$Fast_Food_Res == "ResB")
test <- t.test(resA$Order_Completion,resB$Order_Completion, alternative = "less", mu=0, conf.level = 0.95)
test$statistic
```

d.) 
```{r}
pt(-3.376529, 33)
```
If we were to perform the test again with the same sample size, the probability of getting a test statistic lower than the one we got is 0.00095, which is relatively unlikely. 



e.) We conclude that at any level of significance >0.001 that Restaurant A has shorter wait times than Restaurant B does. 

f.) 
```{r}
test$conf.int
```

Confidence interval comes to (-Inf, -28.47)


